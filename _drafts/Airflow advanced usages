There are some objects in airflow which are usually not in any demo from the offical website, sometimes we need to read the source code to get inspired by some pieces of code.
In this post, I will try to list some of the useful usage that I have tested and hopefully someone land in this page will take them away and use airflow more flexiablely.

# Getting connection details in dag
In my working case, I have some db details that we are noting using airflow operator to fetch data from, instead of that I need to give those db details, such as host, username and password
to another out system as parameters. I don't want to have them in my code, the best concept for keeping those information in airflow is the connections!
So I create a connection in airflow and I will need to get those details in my dag. here is the working example.
- Create a connection from cli
```
$ airflow connections -a --conn_id test_connection_name  --conn_type http --conn_host my_host_name.com --conn_port 8999 --conn_password 123456
```
- Create a dag 
We can use `BaseHook` class method to get connection details by id, A full dag can be found [here](https://gist.github.com/kai-chu/01c0e28f20c80d0360c2c09216144c6a)
```
from airflow.hooks.base_hook import BaseHook
...
connection = BaseHook.get_connection("username_connection")
password = connection.password # This is a getter that returns the unencrypted password.
```

# Render a template by using your own context
We usually provide operator args with a jinja template, if the args is templated, in the doc or code, you will find `template_fields` defined.
such as `template_fields= ['bash_command', 'env']` in the [bash_operator](https://airflow.apache.org/docs/stable/_api/airflow/operators/bash_operator/index.html?highlight=operator#module-airflow.operators.bash_operator)

however, if you have a python code where you want to render your own variables, you can using following method from helpers module.
There is an helper method which is built on top of jinja in airflow, you can import it in your dag file
```
from airflow.utils.helpers import parse_template_string
```
Suppose you have a template string in your dag definition, however, you only know the context when the dag task is running.
For example, the execution_date which is provided in context.ds
Then you can use parse_template_string method to get a template and use the render with context to get your filename as following
```
filename_template='abc-{{my_name}}.csv'

def my_sleeping_function(**context):
  filename_template, filename_jinja_template = parse_template_string(filename_template)
  filename = filename_jinja_template.render(my_name='Kai')

task = PythonOperator(
    task_id='sleep'
    python_callable=my_sleeping_function,
    dag=dag,
)
```


 airflow backfill test-connection-hook -s 2020-08-01 -e 2020-08-01
 
 
 [2020-08-13 21:54:40,333] {standard_task_runner.py:78} INFO - Job 9150: Subtask getDetailsFromConnection
[2020-08-13 21:54:40,390] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: test-connection-hook.getDetailsFromConnection 2020-08-01T00:00:00+00:00 [running]> xsedacof051.se.shb.biz
[2020-08-13 21:54:40,476] {base_hook.py:89} INFO - Using connection to: id: test_connection_name. Host: xsedacof011.se.shb.biz, Port: 8999, Schema: None, Login: None, Password: XXXXXXXX, extra: None
[2020-08-13 21:54:40,478] {logging_mixin.py:112} INFO - 41, 123456
[2020-08-13 21:54:40,478] {python_operator.py:114} INFO - Done. Returned value was: None
[2020-08-13 21:54:40,497] {taskinstance.py:1070} INFO - Marking task as SUCCESS.dag_id=test-connection-hook, task_id=getDetailsFromConnection, execution_date=20200801T000000, start_date=20200813T195440, end_date=20200813T195440
[2020-08-13 21:54:45,256] {local_task_job.py:102} INFO - Task exited with return code 0
